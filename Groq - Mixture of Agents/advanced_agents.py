import os
import time
from typing import Dict, Optional, Generator, List, Any
import json
import math

# LangChain imports
from langchain_groq import ChatGroq
from langchain.memory import ConversationBufferMemory
from langchain.prompts import ChatPromptTemplate
from langchain.tools import Tool
from langchain_community.tools import DuckDuckGoSearchRun as CommunityDuckDuckGoSearchRun
from langchain_community.tools import DuckDuckGoSearchResults as CommunityDuckDuckGoSearchResults
from langchain.agents import create_react_agent, AgentExecutor

# Rich (daha okunabilir Ã§Ä±ktÄ±)
from rich import print as print
from rich.traceback import install as rich_traceback_install
from rich.panel import Panel
from rich.rule import Rule
from rich.table import Table
rich_traceback_install(show_locals=False)


# Rich yardÄ±mcÄ±larÄ±
def print_section(title: str):
    print(Rule(f"[bold cyan]{title}"))


def print_panel(text: str, title: Optional[str] = None, style: str = ""): 
    print(Panel.fit(text, title=title, border_style=style or "cyan"))

GROQ_API_KEY  = "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"
os.environ["GROQ_API_KEY"] = GROQ_API_KEY

# ============================================================================
# GROQ LIMIT YÃ–NETÄ°MÄ° (Free Tier Optimizasyonu)
# ============================================================================

class GroqLimitManager:
    """Groq API limitlerini yÃ¶netir - Free Tier iÃ§in optimize edilmiÅŸ"""
    
    def __init__(self):
        # Free Tier limitleri (konservatif yaklaÅŸÄ±m)
        self.free_tier_limits = {
            'tpm': 6000,  # Tokens per minute
            'rpm': 100,   # Requests per minute (konservatif)
            'max_tokens_per_request': 1500  # Tek istekte max token
        }
        
        self.usage_stats = {
            'tokens_used': 0,
            'requests_made': 0,
            'last_reset': time.time(),
            'current_minute_tokens': 0,
            'current_minute_requests': 0
        }
    
    def estimate_tokens(self, text: str) -> int:
        """Token sayÄ±sÄ±nÄ± tahmin eder (yaklaÅŸÄ±k)"""
        return len(text.split()) * 1.3  # TÃ¼rkÃ§e iÃ§in konservatif tahmin
    
    def check_rate_limits(self, estimated_tokens: int) -> Dict[str, bool]:
        """Rate limitleri kontrol eder"""
        current_time = time.time()
        
        # Dakika sÄ±fÄ±rlama kontrolÃ¼
        if current_time - self.usage_stats['last_reset'] >= 60:
            self.usage_stats['current_minute_tokens'] = 0
            self.usage_stats['current_minute_requests'] = 0
            self.usage_stats['last_reset'] = current_time
        
        # Limit kontrolleri
        can_use_tokens = (
            self.usage_stats['current_minute_tokens'] + estimated_tokens 
            <= self.free_tier_limits['tpm']
        )
        
        can_make_request = (
            self.usage_stats['current_minute_requests'] + 1 
            <= self.free_tier_limits['rpm']
        )
        
        token_size_ok = estimated_tokens <= self.free_tier_limits['max_tokens_per_request']
        
        return {
            'can_proceed': can_use_tokens and can_make_request and token_size_ok,
            'tokens_ok': can_use_tokens,
            'requests_ok': can_make_request,
            'size_ok': token_size_ok
        }
    
    def record_usage(self, tokens_used: int):
        """KullanÄ±mÄ± kaydeder"""
        self.usage_stats['tokens_used'] += tokens_used
        self.usage_stats['requests_made'] += 1
        self.usage_stats['current_minute_tokens'] += tokens_used
        self.usage_stats['current_minute_requests'] += 1
    
    def get_wait_time(self) -> float:
        """Limit aÅŸÄ±mÄ± durumunda bekleme sÃ¼resini hesaplar"""
        time_since_reset = time.time() - self.usage_stats['last_reset']
        return max(0, 60 - time_since_reset)
    
    def get_status(self) -> Dict[str, Any]:
        """Mevcut durumu getirir"""
        current_time = time.time()
        time_since_reset = current_time - self.usage_stats['last_reset']
        
        return {
            'tokens_used_this_minute': self.usage_stats['current_minute_tokens'],
            'requests_made_this_minute': self.usage_stats['current_minute_requests'],
            'tokens_remaining': self.free_tier_limits['tpm'] - self.usage_stats['current_minute_tokens'],
            'requests_remaining': self.free_tier_limits['rpm'] - self.usage_stats['current_minute_requests'],
            'seconds_until_reset': max(0, 60 - time_since_reset),
            'total_tokens_used': self.usage_stats['tokens_used'],
            'total_requests_made': self.usage_stats['requests_made']
        }

# Global limit manager
limit_manager = GroqLimitManager()

print_section("Groq Limit Manager")
print_panel(
    f"TPM: {limit_manager.free_tier_limits['tpm']}\n"
    f"RPM: {limit_manager.free_tier_limits['rpm']}\n"
    f"Max Tokens/Request: {limit_manager.free_tier_limits['max_tokens_per_request']}",
    title="Free Tier Limitleri",
)


# ============================================================================
# GERÃ‡EK AJAN ARAÃ‡LARI (TOOLS)
# ============================================================================

# Web Search Tools (deprecation uyarÄ±sÄ± olmamasÄ± iÃ§in community sÃ¼rÃ¼mleri)
search_tool = CommunityDuckDuckGoSearchRun()
search_results_tool = CommunityDuckDuckGoSearchResults()

# Calculator Tool (Improved)
def safe_calculator(expression: str) -> str:
    """GÃ¼venli matematik hesaplama aracÄ±"""
    try:
        # Girdiyi temizle
        expression = expression.strip()

        # Sadece gÃ¼venli matematiksel ifadelere izin ver
        # Not: Ã–nceki sÃ¼rÃ¼mde '\\s' literal olarak deÄŸerlendirilip boÅŸluk engelleniyordu
        allowed_symbols = set("+-*/.() ")
        if not all(ch.isdigit() or ch in allowed_symbols or ch.isspace() for ch in expression):
            return "Hata: Sadece matematiksel ifadeler kabul edilir (+, -, *, /, sayÄ±lar, parantez)"

        # GÃ¼venlik kontrolÃ¼ - tehlikeli ifadeler
        dangerous_words = ['import', 'exec', 'eval', 'open', 'file', '__']
        lowered = expression.lower()
        if any(word in lowered for word in dangerous_words):
            return "Hata: GÃ¼venlik nedeniyle desteklenmeyen ifade"

        # Hesaplama yap
        result = eval(expression)
        return f"SonuÃ§: {result}"

    except ZeroDivisionError:
        return "Hata: SÄ±fÄ±ra bÃ¶lme hatasÄ±"
    except SyntaxError:
        return "Hata: GeÃ§ersiz matematik ifadesi"
    except Exception as e:
        return f"Hesaplama hatasÄ±: {str(e)}"

calculator_tool = Tool(
    name="Calculator",
    func=safe_calculator,
    description="Matematik hesaplamalarÄ± iÃ§in kullan. Ã–rnek: '2 + 2', '10 * 5', '(3 + 4) * 2'. Sadece matematiksel ifadeler kabul edilir."
)

# Code Execution Tool
def execute_python_code(code: str) -> str:
    """Python kodunu gÃ¼venli ÅŸekilde Ã§alÄ±ÅŸtÄ±r"""
    try:
        # GÃ¼venlik kontrolÃ¼
        dangerous_imports = ['os', 'sys', 'subprocess', 'eval', 'exec', 'open', 'file']
        for dangerous in dangerous_imports:
            if dangerous in code:
                return f"Hata: '{dangerous}' kullanÄ±mÄ± gÃ¼venlik nedeniyle yasak"
        
        # Kodu Ã§alÄ±ÅŸtÄ±r
        exec_globals = {'math': math, 'json': json, 'time': time}
        exec(code, exec_globals)
        return "Kod baÅŸarÄ±yla Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±"
    except Exception as e:
        return f"Kod hatasÄ±: {str(e)}"

code_tool = Tool(
    name="Python_Code_Executor",
    func=execute_python_code,
    description="Python kodunu Ã§alÄ±ÅŸtÄ±r. Sadece gÃ¼venli matematik ve veri iÅŸleme kodlarÄ± kabul edilir."
)

# Text Analysis Tool
def analyze_text(text: str) -> str:
    """Metin analizi yapar"""
    try:
        words = text.split()
        word_count = len(words)
        char_count = len(text)
        sentences = text.count('.') + text.count('!') + text.count('?')
        
        analysis = {
            "kelime_sayisi": word_count,
            "karakter_sayisi": char_count,
            "cumle_sayisi": sentences,
            "ortalama_kelime_uzunlugu": round(char_count / word_count if word_count > 0 else 0, 2)
        }
        
        return f"Metin Analizi: {json.dumps(analysis, indent=2, ensure_ascii=False)}"
    except Exception as e:
        return f"Analiz hatasÄ±: {str(e)}"

text_analysis_tool = Tool(
    name="Text_Analyzer",
    func=analyze_text,
    description="Metin analizi yapar - kelime sayÄ±sÄ±, karakter sayÄ±sÄ±, cÃ¼mle sayÄ±sÄ± vb."
)

## (v1 agent entegrasyonu kaldÄ±rÄ±ldÄ±)

print_section("AraÃ§lar")
table_tools = Table(show_header=True, header_style="bold magenta")
table_tools.add_column("AraÃ§")
table_tools.add_column("Ad")
table_tools.add_row("Search", search_tool.name)
table_tools.add_row("SearchResults", search_results_tool.name)
table_tools.add_row("Calculator", calculator_tool.name)
table_tools.add_row("Code", code_tool.name)
table_tools.add_row("Text Analysis", text_analysis_tool.name)
print(table_tools)


# ============================================================================
# GROQ LIMIT-AWARE AJANLAR (TOOL-BASED)
# ============================================================================

def create_limit_aware_agent(
    name: str,
    system_prompt: str,
    tools: List[Tool],
    model_name: str = "llama-3.3-70b-versatile"
) -> AgentExecutor:
    """Groq limitlerini gÃ¶z Ã¶nÃ¼nde bulunduran ajan oluÅŸturur"""
    
    # Limit-aware LLM oluÅŸtur
    llm = ChatGroq(
        model=model_name, 
        temperature=0.1,
        max_tokens=500,  # Free tier iÃ§in kÄ±sa yanÄ±tlar
        timeout=30  # Timeout ekle
    )
    
    # ReAct agent iÃ§in doÄŸru prompt formatÄ±
    optimized_prompt = ChatPromptTemplate.from_template(f"""{system_prompt}

Mevcut araÃ§lar:
{{tools}}

KullanabileceÄŸin araÃ§lar: {{tool_names}}

Format:
Question: {{input}}
Thought: Ne yapmam gerekiyor?
Action: [araÃ§_adÄ±]
Action Input: [araÃ§_giriÅŸi]
Observation: [araÃ§_Ã§Ä±kÄ±ÅŸÄ±]
Final Answer: [kÄ±sa_yanÄ±t]

{{agent_scratchpad}}""")
    
    # ReAct agent oluÅŸtur
    agent = create_react_agent(
        llm=llm,
        tools=tools,
        prompt=optimized_prompt
    )
    
    return AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=False,
        max_iterations=3,
        handle_parsing_errors=True,
        max_execution_time=30,
        return_intermediate_steps=False
    )

def create_action_agent(
    name: str,
    system_prompt: str,
    tools: List[Tool],
    model_name: str = "llama-3.1-8b-instant"
) -> AgentExecutor:
    """Tool-based gerÃ§ek ajan oluÅŸturur (limit-aware)"""
    return create_limit_aware_agent(name, system_prompt, tools, model_name)

# AraÅŸtÄ±rma AjanÄ± (Improved)
research_agent = create_action_agent(
    name="Research_Agent",
    system_prompt="""Sen araÅŸtÄ±rma uzmanÄ±sÄ±n. Web'de araÅŸtÄ±rma yap ve sonuÃ§larÄ± Ã¶zetle. 
    Her zaman web aramasÄ± yap, sonuÃ§larÄ± analiz et.""",
    tools=[search_tool, Tool(name="duckduckgo_results", func=search_results_tool.run, description="DuckDuckGo'dan JSON sonuÃ§ listesi getir")],
    model_name="llama-3.1-8b-instant"
)

# Analiz AjanÄ± (Improved)
analysis_agent = create_action_agent(
    name="Analysis_Agent",
    system_prompt="""Sen matematik uzmanÄ±sÄ±n. Hesaplama yapmak iÃ§in Calculator aracÄ±nÄ± kullan. 
    Her zaman matematiksel ifadeleri hesapla.""",
    tools=[calculator_tool],
    model_name="llama-3.1-8b-instant"
)

# YaratÄ±cÄ± Ajan (Improved)
creative_agent = create_action_agent(
    name="Creative_Agent",
    system_prompt="""Sen yaratÄ±cÄ± uzmanÄ±sÄ±n. YaratÄ±cÄ± fikirler Ã¼ret ve Ã¶rnekler ver.""",
    tools=[],  # AraÃ§ yok - sadece yaratÄ±cÄ± dÃ¼ÅŸÃ¼nce
    model_name="llama-3.1-8b-instant"
)

print_section("Ajanlar")
table_agents = Table(show_header=True, header_style="bold green")
table_agents.add_column("Ajan")
table_agents.add_column("AraÃ§ SayÄ±sÄ±")
table_agents.add_column("AÃ§Ä±klama")
table_agents.add_row("Research", str(len(research_agent.tools)), "Web araÅŸtÄ±rmasÄ±")
table_agents.add_row("Analysis", str(len(analysis_agent.tools)), "Matematik hesaplamasÄ±")
table_agents.add_row("Creative", str(len(creative_agent.tools)), "YaratÄ±cÄ± dÃ¼ÅŸÃ¼nce")
print(table_agents)
print_panel("Verbose aÃ§Ä±k, daha fazla iterasyon, temiz Ã§Ä±ktÄ±", style="green")


# ============================================================================
# AJANLAR ARASI Ä°ÅBÄ°RLÄ°ÄÄ° SÄ°STEMÄ°
# ============================================================================

class TrueMixtureOfAgents:
    """GerÃ§ek Mixture of Agents sistemi - Groq Free Tier iÃ§in optimize edilmiÅŸ"""
    
    def __init__(self):
        self.agents = {
            'research': research_agent,
            'analysis': analysis_agent,
            'creative': creative_agent
        }
        
        # Ana koordinatÃ¶r ajan (Free Tier Optimized)
        self.coordinator = ChatGroq(
            model="llama-3.1-8b-instant",
            temperature=0.1,
            max_tokens=300,  # KÄ±sa sentez
            timeout=30
        )
        
        # KoordinatÃ¶r iÃ§in prompt template (kÄ±sa ve yapÄ±lÄ±)
        self.coordinator_prompt = ChatPromptTemplate.from_template("""
Sen koordinatÃ¶r ajansÄ±n. FarklÄ± ajan Ã§Ä±ktÄ±larÄ±ndan KISA ve YAPILI bir yanÄ±t Ã¼ret.

KullanÄ±cÄ± Sorusu: {query}
Ajan SonuÃ§larÄ±: {agent_results}
Stil: {style}

Format TalimatlarÄ±:
{format_instructions}

Kurallar:
- Gereksiz giriÅŸ yapma; belirtilen formatÄ± aynen uygula.
""")
        
        # Memory (kÃ¼Ã§Ã¼k boyut)
        self.memory = ConversationBufferMemory(
            memory_key="messages",
            return_messages=True,
            max_token_limit=1000  # Memory limit
        )

    def determine_response_style(self, query: str) -> str:
        q = query.lower()
        if any(k in q for k in [" vs ", "karÅŸÄ±laÅŸtÄ±r", "vs."]):
            return "compare"
        if any(k in q for k in ["hesapla", "+", "-", "*", "/"]):
            return "math"
        if any(k in q for k in ["fikir", "yaratÄ±cÄ±", "Ã¶neri", "proje"]):
            return "creative"
        if any(k in q for k in ["nedir", "nasÄ±l", "nerede", "kim", "ne zaman", "neden", "araÅŸtÄ±r"]):
            return "research"
        return "generic"

    def get_format_instructions(self, style: str) -> str:
        if style == "math":
            return (
                "- Sadece 2 satÄ±r yaz:\n"
                "  1) Cevap: <sonuÃ§>\n"
                "  2) GerekÃ§e: <1 kÄ±sa cÃ¼mle>"
            )
        if style == "research":
            return (
                "- En fazla 5 satÄ±r yaz:\n"
                "  1) Ã–zet: <1 cÃ¼mle>\n"
                "  2-4) â€¢ <kÄ±sa madde>\n"
                "  5) Ã–neri: <1 cÃ¼mle>"
            )
        if style == "compare":
            return (
                "- En fazla 6 satÄ±r yaz:\n"
                "  1) Ã–zet: <1 cÃ¼mle>\n"
                "  2-3) React: â€¢ <kÄ±sa madde>\n"
                "  4-5) Vue: â€¢ <kÄ±sa madde>\n"
                "  6) Ã–neri: <1 cÃ¼mle>"
            )
        if style == "creative":
            return (
                "- En fazla 4 satÄ±r yaz:\n"
                "  1) Ã–zet: <1 cÃ¼mle>\n"
                "  2-4) â€¢ <kÄ±sa fikir>"
            )
        return (
            "- En fazla 4 satÄ±r yaz:\n"
            "  1) Cevap: <1 cÃ¼mle>\n"
            "  2-4) â€¢ <kÄ±sa destekleyici noktalar>"
        )
    
    def smart_agent_selection(self, query: str) -> List[str]:
        """Soruya gÃ¶re hangi ajanlarÄ± kullanacaÄŸÄ±nÄ± belirler"""
        query_lower = query.lower()
        selected_agents = []
        
        # AraÅŸtÄ±rma anahtar kelimeleri
        research_keywords = ['araÅŸtÄ±r', 'bul', 'nedir', 'nasÄ±l', 'nerede', 'kim', 'ne zaman', 'neden', 'hangi', 'nelerdir', 'liste', 'kaynak', 'referans']
        if any(keyword in query_lower for keyword in research_keywords):
            selected_agents.append('research')
        
        # Analiz anahtar kelimeleri
        analysis_keywords = ['hesapla', 'analiz', 'karÅŸÄ±laÅŸtÄ±r', 'deÄŸerlendir', 'matematik', 'sayÄ±', 'istatistik']
        if any(keyword in query_lower for keyword in analysis_keywords):
            selected_agents.append('analysis')
        
        # YaratÄ±cÄ± anahtar kelimeleri
        creative_keywords = ['fikir', 'yaratÄ±cÄ±', 'Ã§Ã¶zÃ¼m', 'Ã¶neri', 'tasarÄ±m', 'plan', 'strateji']
        if any(keyword in query_lower for keyword in creative_keywords):
            selected_agents.append('creative')
        
        # EÄŸer hiÃ§bir ajan seÃ§ilmediyse, hepsini kullan
        if not selected_agents:
            selected_agents = ['research', 'analysis', 'creative']
        
        return selected_agents
    
    def collaborative_workflow(self, query: str) -> Generator[str, None, None]:
        """Ajanlar gerÃ§ek iÅŸbirliÄŸi yapar - Free Tier Optimized"""
        
        # Token limit kontrolÃ¼
        estimated_tokens = limit_manager.estimate_tokens(query)
        limit_check = limit_manager.check_rate_limits(estimated_tokens)
        
        if not limit_check['can_proceed']:
            wait_time = limit_manager.get_wait_time()
            yield f"â³ Rate limit aÅŸÄ±ldÄ±. {wait_time:.0f} saniye bekleyin...\\n"
            return
        
        # 1. Hangi ajanlarÄ± kullanacaÄŸÄ±mÄ±zÄ± belirle (max 2 ajan - token tasarrufu)
        selected_agents = self.smart_agent_selection(query)[:2]  # Max 2 ajan
        used_research = 'research' in selected_agents
        
        agent_results = {}
        
        # 2. Her ajanÄ± Ã§alÄ±ÅŸtÄ±r (limit-aware)
        for agent_name in selected_agents:
            
            try:
                # Token kontrolÃ¼
                agent_tokens = limit_manager.estimate_tokens(query)
                if not limit_manager.check_rate_limits(agent_tokens)['can_proceed']:
                    continue
                
                # AjanÄ± Ã§alÄ±ÅŸtÄ±r
                result = self.agents[agent_name].invoke({"input": query})
                
                # Sonucu temizle ve kaydet
                if isinstance(result, dict) and 'output' in result:
                    clean_output = result['output'].replace("Agent stopped due to iteration limit or time limit.", "").strip()
                    agent_results[agent_name] = clean_output
                else:
                    agent_results[agent_name] = str(result)
                
                # KullanÄ±mÄ± kaydet
                limit_manager.record_usage(agent_tokens)
                
                # sessiz Ã§Ä±ktÄ±
                
            except Exception as e:
                agent_results[agent_name] = f"Hata: {str(e)}"
        
        # 3. SonuÃ§larÄ± sentezle (kÄ±sa)
        if agent_results:
            
            # KoordinatÃ¶r prompt ile sentez yap
            agent_results_text = "\\n".join([f"{name}: {result}" for name, result in agent_results.items()])
            # Research ajanÄ± seÃ§ildiyse stili research'a zorla
            style = 'research' if used_research else self.determine_response_style(query)
            format_instructions = self.get_format_instructions(style)

            try:
                # Ana koordinatÃ¶r ile sentez yap
                synthesis_response = self.coordinator.invoke(
                    self.coordinator_prompt.format(
                        query=query,
                        agent_results=agent_results_text,
                        style=style,
                        format_instructions=format_instructions
                    )
                )
                
                # Token kullanÄ±mÄ±nÄ± kaydet
                synthesis_tokens = limit_manager.estimate_tokens(query + agent_results_text + synthesis_response.content)
                limit_manager.record_usage(synthesis_tokens)

                # Research ajanÄ± kullanÄ±ldÄ±ysa kÄ±sa yanÄ±t + altta 3 kaynak linki gÃ¶ster
                if used_research:
                    try:
                        raw = search_results_tool.run(query)
                        lines = []
                        if isinstance(raw, list):
                            for item in raw[:3]:
                                url = (item.get('link') or item.get('href') or item.get('url') or '').strip()
                                title = (item.get('title') or item.get('source') or url).strip()
                                if url:
                                    lines.append(f"- [{title}]({url})")
                        elif isinstance(raw, dict) and 'results' in raw:
                            for item in raw['results'][:3]:
                                url = (item.get('link') or item.get('href') or item.get('url') or '').strip()
                                title = (item.get('title') or item.get('source') or url).strip()
                                if url:
                                    lines.append(f"- [{title}]({url})")
                        sources = "\\n".join(lines)
                        if sources:
                            yield f"{synthesis_response.content}\\nKaynaklar:\\n{sources}\\n"
                        else:
                            yield f"{synthesis_response.content}\\n"
                    except Exception:
                        yield f"{synthesis_response.content}\\n"
                else:
                    yield f"{synthesis_response.content}\\n"
                
                # Memory'ye kaydet (kÄ±sa)
                self.memory.save_context(
                    {'input': query}, 
                    {'output': synthesis_response.content[:500]}  # KÄ±sa kayÄ±t
                )
                
            except Exception as e:
                yield f"Hata: {str(e)}\\n"
        else:
            yield f"Hata: HiÃ§bir ajan Ã§alÄ±ÅŸmadÄ±.\\n"
        
        # Limit durumu gÃ¶ster
        status = limit_manager.get_status()
        yield f"\\nğŸ“Š {int(status['tokens_remaining'])} token kaldÄ±, {int(status['seconds_until_reset'])}s\\n"

print("âœ… TrueMixtureOfAgents sistemi hazÄ±r!")
print("ğŸ¤– Ajanlar gerÃ§ek eylemler yapacak")


# ============================================================================
# PERFORMANS OPTÄ°MÄ°ZASYONLARI
# ============================================================================

class OptimizedAgentSystem:
    """Optimize edilmiÅŸ agent sistemi"""
    
    def __init__(self):
        self.base_system = TrueMixtureOfAgents()
        self.cache = {}
        self.performance_stats = {
            'total_queries': 0,
            'avg_response_time': 0,
            'cache_hits': 0
        }
    
    def check_token_limit(self, query: str) -> bool:
        """Token limitini kontrol et - Groq Free Tier iÃ§in optimize edilmiÅŸ"""
        estimated_tokens = limit_manager.estimate_tokens(query)
        limit_check = limit_manager.check_rate_limits(estimated_tokens)
        return limit_check['can_proceed']
    
    def get_cached_response(self, query: str) -> Optional[str]:
        """Cache'den yanÄ±t al"""
        query_hash = hash(query.lower().strip())
        if query_hash in self.cache:
            self.performance_stats['cache_hits'] += 1
            return self.cache[query_hash]
        return None
    
    def cache_response(self, query: str, response: str):
        """YanÄ±tÄ± cache'e kaydet"""
        query_hash = hash(query.lower().strip())
        self.cache[query_hash] = response
    
    def optimized_chat_stream(self, query: str) -> Generator[str, None, None]:
        """Optimize edilmiÅŸ chat stream"""
        start_time = time.time()
        
        # Token limit kontrolÃ¼ (Groq Free Tier)
        if not self.check_token_limit(query):
            status = limit_manager.get_status()
            yield f"âŒ Token limiti aÅŸÄ±ldÄ±. {status['seconds_until_reset']:.0f} saniye bekleyin."
            yield f"ğŸ“Š Mevcut durum: {status['tokens_remaining']} token kaldÄ±"
            return
        
        # Cache kontrolÃ¼
        cached_response = self.get_cached_response(query)
        if cached_response:
            yield f"âš¡ Cache'den yanÄ±t (HÄ±zlÄ±!)\\n{cached_response}"
            return
        
        # GerÃ§ek iÅŸlemi yap
        response_parts = []
        
        for chunk in self.base_system.collaborative_workflow(query):
            yield chunk
            response_parts.append(chunk)
        
        # Cache'e kaydet
        full_response = ''.join(response_parts)
        self.cache_response(query, full_response)
        
        # Performans istatistikleri
        execution_time = time.time() - start_time
        self.performance_stats['total_queries'] += 1
        
        # Ortalama sÃ¼reyi gÃ¼ncelle
        total_queries = self.performance_stats['total_queries']
        current_avg = self.performance_stats['avg_response_time']
        self.performance_stats['avg_response_time'] = (
            (current_avg * (total_queries - 1) + execution_time) / total_queries
        )
        
        yield f"\\n\\nğŸ“Š Performans: {execution_time:.2f}s | Cache: {self.performance_stats['cache_hits']}/{total_queries}"
    
    def get_stats(self) -> Dict[str, Any]:
        """Performans istatistiklerini getir"""
        return self.performance_stats.copy()

# Optimize edilmiÅŸ sistem
optimized_system = OptimizedAgentSystem()

print_panel("Cache sistemi aktif\nPerformans izleme aktif", title="Optimize Sistem", style="magenta")


# ============================================================================
# TEST FONKSÄ°YONLARI
# ============================================================================

def test_agent_system():
    """Test the agent system with various queries"""
    print("ğŸ§ª Test BaÅŸlÄ±yor...")
    
    test_queries = [
        "Python'da machine learning iÃ§in hangi kÃ¼tÃ¼phaneleri kullanmalÄ±yÄ±m?",
        "2 + 2 * 3 hesapla",
        "Vue.js ile React arasÄ±ndaki farklar neler?"
    ]
    
    for i, query in enumerate(test_queries, 1):
        print(f"\\n{'='*50}")
        print(f"ğŸ§ª TEST {i}: {query}")
        print(f"{'='*50}")
        
        # Test the system
        responses = list(optimized_system.optimized_chat_stream(query))
        
        # Print all responses
        for response in responses:
            print(response)
        
        print(f"\\nâœ… Test {i} tamamlandÄ±!")
        
        # Wait between tests
        time.sleep(2)
    
    print(f"\\nğŸ“Š Final Limit Durumu: {limit_manager.get_status()['tokens_remaining']:.1f} token kaldÄ±")
    print(f"\\nğŸ“Š Ä°statistikler: {optimized_system.get_stats()}")

def quick_test():
    """Quick test with a single query"""
    print("ğŸ§ª HÄ±zlÄ± Test BaÅŸlÄ±yor...")
    print(f"ğŸ“Š BaÅŸlangÄ±Ã§ Durumu: {limit_manager.get_status()['tokens_remaining']:.1f} token kaldÄ±")
    
    query = "2 + 2 * 3 hesapla"
    print(f"\\nğŸ”¹ Test Sorusu: {query}")
    
    responses = list(optimized_system.optimized_chat_stream(query))
    for response in responses:
        print(response)
    
    print(f"\\nâœ… Test tamamlandÄ±!")
    print(f"ğŸ“Š Final Durum: {limit_manager.get_status()['tokens_remaining']:.1f} token kaldÄ±")

def test_agents():
    """Test individual agents"""
    print("ğŸ§ª Ajan Testi BaÅŸlÄ±yor...")
    
    # Test calculator
    print("\\nğŸ”¹ Calculator Test:")
    result = calculator_tool.run("2 + 2 * 3")
    print(f"SonuÃ§: {result}")
    
    # Test search
    print("\\nğŸ”¹ Search Test:")
    try:
        search_result = search_tool.run("Python machine learning")
        print(f"SonuÃ§: {search_result[:200]}...")
    except Exception as e:
        print(f"Hata: {e}")
    
    print("\\nâœ… Ajan testi tamamlandÄ±!")

def clean_test():
    """Temiz ve okunabilir test"""
    print("ğŸ§ª Temiz Test BaÅŸlÄ±yor...")
    print(f"ğŸ“Š BaÅŸlangÄ±Ã§ Durumu: {limit_manager.get_status()['tokens_remaining']:.1f} token kaldÄ±")
    
    query = "2 + 2 * 3 hesapla"
    print(f"\\nğŸ”¹ Test Sorusu: {query}")
    
    responses = list(optimized_system.optimized_chat_stream(query))
    for response in responses:
        print(response)
    
    print(f"\\nâœ… Test tamamlandÄ±!")
    print(f"ğŸ“Š Final Durum: {limit_manager.get_status()['tokens_remaining']:.1f} token kaldÄ±")

def test_imports():
    """Test if all imports are working"""
    print("ğŸ§ª Import Test BaÅŸlÄ±yor...")
    
    try:
        # Test LangChain imports
        from langchain_groq import ChatGroq
        from langchain.memory import ConversationBufferMemory
        from langchain.prompts import ChatPromptTemplate
        from langchain.tools import Tool
        from langchain_community.tools import DuckDuckGoSearchRun as CommunityDuckDuckGoSearchRun
        from langchain.agents import create_react_agent, AgentExecutor
        
        print("âœ… TÃ¼m LangChain import'larÄ± baÅŸarÄ±lÄ±!")
        
        # Test basic functionality
        llm = ChatGroq(model="llama-3.1-8b-instant", temperature=0.1, max_tokens=100)
        response = llm.invoke("Merhaba")
        print(f"âœ… LLM test baÅŸarÄ±lÄ±: {response.content[:50]}...")
        
    except Exception as e:
        print(f"âŒ Import hatasÄ±: {e}")
    
    print("\\nâœ… Import testi tamamlandÄ±!")

print_panel("Temiz test, hÄ±zlÄ± test ve tam test fonksiyonlarÄ± hazÄ±r", title="Test FonksiyonlarÄ±")

# ============================================================================
# Ä°NTERAKTÄ°F CHAT SÄ°STEMÄ°
# ============================================================================

def interactive_chat():
    """Ä°nteraktif chat sistemi"""
    print("ğŸ‰ Ä°nteraktif Chat Sistemi BaÅŸlÄ±yor!")
    print("ğŸ’¡ 'quit' yazarak Ã§Ä±kabilirsiniz")
    print("ğŸ’¡ 'stats' yazarak istatistikleri gÃ¶rebilirsiniz")
    print("ğŸ’¡ 'clear' yazarak memory'yi temizleyebilirsiniz")
    print("="*60)
    
    while True:
        try:
            user_input = input("\\nğŸ¤– Sorunuz: ").strip()
            
            if user_input.lower() == 'quit':
                print("ğŸ‘‹ GÃ¶rÃ¼ÅŸÃ¼rÃ¼z!")
                break
            elif user_input.lower() == 'stats':
                stats = optimized_system.get_stats()
                limit_status = limit_manager.get_status()
                print(f"\\nğŸ“Š Ä°statistikler: {stats}")
                print(f"ğŸ“Š Limit Durumu: {limit_status}")
                continue
            elif user_input.lower() == 'clear':
                optimized_system.base_system.memory.clear()
                print("ğŸ§¹ Memory temizlendi!")
                continue
            elif not user_input:
                print("â“ LÃ¼tfen bir soru yazÄ±n!")
                continue
            
            print("\\n" + "="*60)
            print(f"ğŸ¤– Soru: {user_input}")
            print("="*60)
            
            # Chat stream
            responses = list(optimized_system.optimized_chat_stream(user_input))
            for response in responses:
                print(response)
                
        except KeyboardInterrupt:
            print("\\nğŸ‘‹ GÃ¶rÃ¼ÅŸÃ¼rÃ¼z!")
            break
        except Exception as e:
            print(f"âŒ Hata: {e}")

print_panel("interactive_chat() ile baÅŸlat", title="Ä°nteraktif Chat", style="green")


# ============================================================================
# KULLANIM TALÄ°MATLARI
# ============================================================================

print_panel(
    "GerÃ§ek ajanlar â€¢ Groq optimize â€¢ Cache â€¢ Ä°zleme â€¢ Temiz Ã§Ä±ktÄ±",
    title="GeliÅŸmiÅŸ Mixture of Agents",
)

print_panel("Sistem hazÄ±r", style="green")


# ============================================================================
# SÄ°STEMÄ° TEST ET
# ============================================================================

def test_agent_system():
    """Agent sistemini test et"""
    
    test_queries = [
        "Python'da machine learning iÃ§in hangi kÃ¼tÃ¼phaneleri kullanmalÄ±yÄ±m?",
        "2 + 2 * 3 hesapla",
        "React vs Vue.js karÅŸÄ±laÅŸtÄ±rmasÄ± yap"
    ]
    
    for i, query in enumerate(test_queries, 1):
        print(f"\\n{'='*50}")
        print(f"ğŸ§ª TEST {i}: {query}")
        print(f"{'='*50}")
        
        for chunk in optimized_system.optimized_chat_stream(query):
            print(chunk, end="")
        
        print(f"\\n\\nğŸ“Š Ä°statistikler: {optimized_system.get_stats()}")

print("ğŸ§ª Test sistemi hazÄ±r. 'test_agent_system()' Ã§alÄ±ÅŸtÄ±rarak test edebilirsiniz.")


test_agent_system()

# ============================================================================
# Ä°NTERAKTÄ°F CHAT SÄ°STEMÄ°
# ============================================================================

def interactive_chat():
    """Ä°nteraktif chat sistemi"""
    
    print("ğŸ¤– GeliÅŸmiÅŸ Mixture of Agents Sistemi")
    print("=" * 50)
    print("Komutlar:")
    print("- 'quit' veya 'exit': Ã‡Ä±kÄ±ÅŸ")
    print("- 'stats': Performans istatistikleri")
    print("- 'clear': Cache'i temizle")
    print("=" * 50)
    
    while True:
        try:
            user_input = input("\\nğŸ”¹ Sorunuz: ")
            
            if user_input.lower() in ['quit', 'exit', 'Ã§Ä±kÄ±ÅŸ']:
                print("\\nğŸ‘‹ GÃ¶rÃ¼ÅŸÃ¼rÃ¼z!")
                break
            
            elif user_input.lower() == 'stats':
                stats = optimized_system.get_stats()
                print(f"\\nğŸ“Š Performans Ä°statistikleri:")
                print(f"Toplam Sorgu: {stats['total_queries']}")
                print(f"Ortalama SÃ¼re: {stats['avg_response_time']:.2f}s")
                print(f"Cache Hit OranÄ±: {stats['cache_hits']}/{stats['total_queries']}")
                continue
            
            elif user_input.lower() == 'clear':
                optimized_system.cache.clear()
                print("\\nğŸ—‘ï¸ Cache temizlendi!")
                continue
            
            elif not user_input.strip():
                print("\\nâŒ LÃ¼tfen bir soru yazÄ±n.")
                continue
            
            print(f"\\nğŸ‘¤ KullanÄ±cÄ±: {user_input}")
            print(f"ğŸ¤– AI: ", end="")
            
            # YanÄ±tÄ± al ve gÃ¶ster
            for chunk in optimized_system.optimized_chat_stream(user_input):
                print(chunk, end="")
            
            print("\\n")
            
        except KeyboardInterrupt:
            print("\\n\\nğŸ‘‹ GÃ¶rÃ¼ÅŸÃ¼rÃ¼z!")
            break
        except Exception as e:
            print(f"\\nâŒ Hata: {str(e)}")

print("ğŸ’¬ Ä°nteraktif chat hazÄ±r. 'interactive_chat()' Ã§alÄ±ÅŸtÄ±rarak baÅŸlayabilirsiniz.")


# ## ğŸš€ KullanÄ±m TalimatlarÄ±
# 
# ### 1. **Test Etmek Ä°Ã§in:**
# ```python
# test_agent_system()
# ```
# 
# ### 2. **Ä°nteraktif Chat Ä°Ã§in:**
# ```python
# interactive_chat()
# ```
# 
# ### 3. **Performans Ä°statistikleri:**
# ```python
# optimized_system.get_stats()
# ```
# 
# ### 4. **Groq Limit Durumu:**
# ```python
# limit_manager.get_status()
# ```
# 
# ## ğŸ¯ Ã–zellikler (Groq Free Tier Optimized)
# 
# âœ… **GerÃ§ek Tool-Based Ajanlar** - Sadece text deÄŸil, gerÃ§ek eylemler
# âœ… **Groq Limit YÃ¶netimi** - [Free Tier limitleri](https://console.groq.com/settings/limits) iÃ§in optimize
# âœ… **AkÄ±llÄ± Ajan SeÃ§imi** - Soruya gÃ¶re hangi ajanlarÄ± kullanacaÄŸÄ±nÄ± belirler
# âœ… **Ä°ÅŸbirliÄŸi Sistemi** - Ajanlar gerÃ§ekten iÅŸbirliÄŸi yapar
# âœ… **Cache Sistemi** - HÄ±zlÄ± yanÄ±tlar iÃ§in
# âœ… **Performans Ä°zleme** - GerÃ§ek zamanlÄ± istatistikler
# âœ… **Rate Limit KorumasÄ±** - 6000 TPM, 100 RPM limitleri
# âœ… **Token Tasarrufu** - KÄ±sa yanÄ±tlar, optimize edilmiÅŸ promptlar
# 
# ## ğŸ”§ AraÃ§lar (Free Tier Optimized)
# 
# - ğŸ” **Web Search** - GerÃ§ek zamanlÄ± araÅŸtÄ±rma
# - ğŸ§® **Calculator** - GÃ¼venli matematik hesaplamalarÄ±
# 
# ## ğŸ“Š Groq Free Tier Limitleri
# 
# - **TPM**: 6,000 tokens/dakika
# - **RPM**: 100 requests/dakika  
# - **Max Tokens/Request**: 1,500
# - **Model**: llama-3.1-8b-instant (hÄ±zlÄ± ve ekonomik)
# 
# Bu sistem **Groq Free Tier** iÃ§in optimize edilmiÅŸ gerÃ§ek **Mixture of Agents**! ğŸ‰
# 
# **Limit kontrolÃ¼ iÃ§in**: [Groq Console](https://console.groq.com/settings/limits)
# 


# ============================================================================
# HIZLI TEST
# ============================================================================

def quick_test():
    """HÄ±zlÄ± test fonksiyonu"""
    print("ğŸ§ª HÄ±zlÄ± Test BaÅŸlÄ±yor...")
    
    # Limit durumunu kontrol et
    status = limit_manager.get_status()
    print(f"ğŸ“Š BaÅŸlangÄ±Ã§ Durumu: {status['tokens_remaining']} token kaldÄ±")
    
    # Basit bir test
    test_query = "2 + 2 * 3 hesapla"
    print(f"\\nğŸ”¹ Test Sorusu: {test_query}")
    
    try:
        for chunk in optimized_system.optimized_chat_stream(test_query):
            print(chunk, end="")
        
        print(f"\\n\\nâœ… Test tamamlandÄ±!")
        
        # Final durum
        final_status = limit_manager.get_status()
        print(f"ğŸ“Š Final Durum: {final_status['tokens_remaining']} token kaldÄ±")
        
    except Exception as e:
        print(f"âŒ Test hatasÄ±: {str(e)}")

print("âš¡ HÄ±zlÄ± test hazÄ±r. 'quick_test()' Ã§alÄ±ÅŸtÄ±rarak test edebilirsiniz.")


# ============================================================================
# TEMÄ°Z TEST FONKSÄ°YONU
# ============================================================================

def clean_test():
    """Temiz ve okunabilir test"""
    print("ğŸ§ª TEMÄ°Z TEST BAÅLIYOR...")
    print("="*60)
    
    # Test 1: Basit matematik
    print("\\nğŸ”¢ TEST 1: Basit Matematik")
    print("-" * 30)
    query1 = "2 + 2 * 3 hesapla"
    print(f"Soru: {query1}")
    
    try:
        for chunk in optimized_system.optimized_chat_stream(query1):
            print(chunk, end="")
    except Exception as e:
        print(f"Hata: {e}")
    
    print("\\n" + "="*60)
    
    # Test 2: AraÅŸtÄ±rma
    print("\\nğŸ” TEST 2: AraÅŸtÄ±rma")
    print("-" * 30)
    query2 = "Python ML kÃ¼tÃ¼phaneleri"
    print(f"Soru: {query2}")
    
    try:
        for chunk in optimized_system.optimized_chat_stream(query2):
            print(chunk, end="")
    except Exception as e:
        print(f"Hata: {e}")
    
    print("\\n" + "="*60)
    
    # Test 3: YaratÄ±cÄ±lÄ±k
    print("\\nğŸ’¡ TEST 3: YaratÄ±cÄ±lÄ±k")
    print("-" * 30)
    query3 = "YaratÄ±cÄ± proje fikirleri"
    print(f"Soru: {query3}")
    
    try:
        for chunk in optimized_system.optimized_chat_stream(query3):
            print(chunk, end="")
    except Exception as e:
        print(f"Hata: {e}")
    
    print("\\n" + "="*60)
    print("âœ… TÃœM TESTLER TAMAMLANDI!")
    
    # Final durum
    status = limit_manager.get_status()
    print(f"\\nğŸ“Š Final Durum: {status['tokens_remaining']} token kaldÄ±")

print("ğŸ§ª Temiz test hazÄ±r. 'clean_test()' Ã§alÄ±ÅŸtÄ±rarak test edebilirsiniz.")


quick_test()

# ============================================================================
# AJANLARI TEST ET
# ============================================================================

def test_agents():
    """AjanlarÄ± test et"""
    print("ğŸ§ª Ajan Testi BaÅŸlÄ±yor...")
    
    # Test sorgularÄ±
    test_queries = [
        "2 + 2 * 3 hesapla",
        "Python ML kÃ¼tÃ¼phaneleri neler?",
        "YaratÄ±cÄ± proje fikirleri ver"
    ]
    
    for i, query in enumerate(test_queries, 1):
        print(f"\\n{'='*50}")
        print(f"ğŸ§ª TEST {i}: {query}")
        print(f"{'='*50}")
        
        try:
            for chunk in optimized_system.optimized_chat_stream(query):
                print(chunk, end="")
            
            print(f"\\n\\nâœ… Test {i} tamamlandÄ±!")
            
        except Exception as e:
            print(f"âŒ Test {i} hatasÄ±: {str(e)}")
    
    # Final durum
    final_status = limit_manager.get_status()
    print(f"\\nğŸ“Š Final Limit Durumu: {final_status['tokens_remaining']} token kaldÄ±")

print("ğŸ§ª Ajan testi hazÄ±r. 'test_agents()' Ã§alÄ±ÅŸtÄ±rarak test edebilirsiniz.")


test_agents()