"""
YouTube Video Soru-Cevap Agent Sistemi
Bu sistem YouTube video linkinden transcript Ã§Ä±karÄ±p, iÃ§erik hakkÄ±nda soru-cevap yapar.
"""

import os
import re
from typing import List, Dict, Any, Optional, TypedDict
from urllib.parse import urlparse, parse_qs

from youtube_transcript_api import YouTubeTranscriptApi
from pytube import YouTube
import tiktoken

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain.embeddings.base import Embeddings
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
import google.generativeai as genai

from langgraph.graph import StateGraph, END

import httpx

class LMStudioEmbeddings(Embeddings):
    """LM Studio iÃ§in Ã¶zel embedding sÄ±nÄ±fÄ±"""
    
    def __init__(self, base_url: str, model_name: str):
        self.base_url = base_url
        self.model_name = model_name
        self.client = httpx.Client(timeout=60.0)
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """Metinleri embedding'e Ã§evirir"""
        embeddings = []
        for text in texts:
            try:
                response = self.client.post(
                    f"{self.base_url}/embeddings",
                    json={
                        "model": self.model_name,
                        "input": text
                    }
                )
                
                if response.status_code == 200:
                    data = response.json()
                    embedding = data["data"][0]["embedding"]
                    embeddings.append(embedding)
                else:
                    print(f"âŒ Embedding hatasÄ±: {response.status_code}")
                    # Hata durumunda dummy embedding
                    embeddings.append([0.0] * 1024)  # VarsayÄ±lan boyut
            except Exception as e:
                print(f"âŒ Embedding isteÄŸi hatasÄ±: {e}")
                embeddings.append([0.0] * 1024)
        
        return embeddings
    
    def embed_query(self, text: str) -> List[float]:
        """Tek bir metni embedding'e Ã§evirir"""
        return self.embed_documents([text])[0]

class VideoQAState(TypedDict):
    """Agent state yapÄ±sÄ±"""
    video_url: str
    video_title: str
    transcript: str
    chunks: List[Document]
    vectorstore: Optional[Any]
    question: str
    relevant_chunks: List[str]
    answer: str
    conversation_history: List[Dict[str, str]]
    key_insights: List[str]  # Ana fikirler
    error_message: str

class YouTubeQAAgent:
    """YouTube Video Soru-Cevap Agent Sistemi"""
    
    def __init__(self, 
                 api_key: str = None,
                 provider: str = "lm_studio",  # "lm_studio" veya "gemini"
                 lm_studio_url: str = "http://localhost:1234/v1",
                 model_name: str = "gemma-3n-e4b",
                 embedding_model: str = "text-embedding-mxbai-embed-large-v1"):
        """
        Args:
            api_key: Gemini API key (sadece Gemini modu iÃ§in gerekli)
            provider: "lm_studio" veya "gemini"
            lm_studio_url: LM Studio API endpoint'i
            model_name: KullanÄ±lacak LLM model adÄ±
            embedding_model: KullanÄ±lacak embedding model adÄ±
        """
        self.provider = provider
        self.lm_studio_url = lm_studio_url
        self.model_name = model_name
        self.embedding_model = embedding_model
        
        if provider == "lm_studio":
            # LM Studio iÃ§in yapÄ±landÄ±rma
            print("ğŸ”µ LM Studio modu etkinleÅŸtirildi")
            print(f"ğŸ”— Endpoint: {lm_studio_url}")
            print(f"ğŸ¤– LLM Model: {model_name}")
            print(f"ğŸ§  Embedding Model: {embedding_model}")
            
            # LM Studio iÃ§in ChatOpenAI benzeri client
            from langchain_openai import ChatOpenAI
            self.llm = ChatOpenAI(
                base_url=lm_studio_url,
                api_key="lm-studio",  # LM Studio iÃ§in dummy key
                model=model_name,
                temperature=0.1,
                max_tokens=2000
            )
            
            # LM Studio embeddings kullan
            self.embeddings = LMStudioEmbeddings(lm_studio_url, embedding_model)
            print("âœ… LM Studio embeddings yapÄ±landÄ±rÄ±ldÄ±")
            
        elif provider == "gemini":
            # Gemini iÃ§in yapÄ±landÄ±rma
            if not api_key:
                raise ValueError("Gemini API key gerekli")
            
            print("ğŸ”µ Google Gemini modu etkinleÅŸtirildi")
            print(f"ğŸ¤– Model: {model_name}")
            
            # Gemini API key'i ayarla
            genai.configure(api_key=api_key)
            os.environ["GOOGLE_API_KEY"] = api_key
            
            # Gemini LLM
            self.llm = ChatGoogleGenerativeAI(
                model=model_name if model_name.startswith("gemini") else "gemini-2.5-flash",
                temperature=0.1,
                max_tokens=2000
            )
            
            # Gemini embeddings
            self.embeddings = GoogleGenerativeAIEmbeddings(
                model="models/embedding-001"
            )
            print("âœ… Gemini LLM ve embeddings yapÄ±landÄ±rÄ±ldÄ±")
            
        else:
            raise ValueError(f"Desteklenmeyen provider: {provider}")
        
        # Text splitter
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len,
        )
        
        # Token sayacÄ±
        self.encoding = tiktoken.encoding_for_model("gpt-4o-mini")
        
        # Graph'Ä± oluÅŸtur
        self.graph = self._build_graph()
    
    def extract_video_id(self, url: str) -> Optional[str]:
        """YouTube URL'den video ID'sini Ã§Ä±karÄ±r"""
        try:
            parsed_url = urlparse(url)
            
            if parsed_url.hostname in ['www.youtube.com', 'youtube.com']:
                if parsed_url.path == '/watch':
                    return parse_qs(parsed_url.query).get('v', [None])[0]
                elif parsed_url.path.startswith('/embed/'):
                    return parsed_url.path.split('/embed/')[1]
            elif parsed_url.hostname in ['youtu.be']:
                return parsed_url.path[1:]
            
            return None
        except Exception as e:
            print(f"âŒ URL parse hatasÄ±: {e}")
            return None
    
    def get_video_info(self, state: VideoQAState) -> VideoQAState:
        """Video bilgilerini alÄ±r"""
        try:
            print("ğŸ”µ Video bilgileri alÄ±nÄ±yor...")
            
            video_id = self.extract_video_id(state["video_url"])
            if not video_id:
                state["error_message"] = "GeÃ§ersiz YouTube URL"
                return state
            
            # Video baÅŸlÄ±ÄŸÄ±nÄ± al - farklÄ± yÃ¶ntemler dene
            try:
                # Ä°lk yÃ¶ntem: pytube
                yt = YouTube(state["video_url"])
                state["video_title"] = yt.title
                print(f"âœ… Video bulundu (pytube): {state['video_title']}")
            except Exception as e1:
                print(f"âš ï¸ Pytube hatasÄ±: {e1}")
                # Son Ã§are: sadece video ID
                state["video_title"] = f"YouTube Video ({video_id})"
                print(f"âš ï¸ Video ID kullanÄ±lÄ±yor: {state['video_title']}")
            
        except Exception as e:
            state["error_message"] = f"Video bilgisi alÄ±namadÄ±: {str(e)}"
            print(f"âŒ Hata: {state['error_message']}")
        
        return state
    
    def extract_transcript(self, state: VideoQAState) -> VideoQAState:
        """YouTube video transcript'ini Ã§Ä±karÄ±r"""
        try:
            print("ğŸ”µ Video transcript'i Ã§Ä±karÄ±lÄ±yor...")
            
            video_id = self.extract_video_id(state["video_url"])
            if not video_id:
                state["error_message"] = "Video ID Ã§Ä±karÄ±lamadÄ±"
                return state
            
            # Yeni API kullanÄ±mÄ±
            ytt_api = YouTubeTranscriptApi()
            fetched_transcript = None
            
            # FarklÄ± dilleri dene
            languages_to_try = ['tr', 'en']
            
            for lang in languages_to_try:
                try:
                    print(f"ğŸ“Dil deneniyor: {lang}")
                    fetched_transcript = ytt_api.fetch(video_id, languages=[lang])
                    print(f"âœ…Transcript bulundu ({lang})")
                    break
                except Exception as lang_error:
                    print(f"ğŸ“{lang} dili baÅŸarÄ±sÄ±z: {lang_error}")
                    continue
            
            # EÄŸer hiÃ§ dil bulunamazsa, mevcut transcript'leri listele ve ilkini al
            if not fetched_transcript:
                try:
                    print("âš ï¸Mevcut transcript'ler listeleniyor...")
                    transcript_list = ytt_api.list(video_id)
                    
                    # Ä°lk mevcut transcript'i al
                    for transcript in transcript_list:
                        try:
                            fetched_transcript = transcript.fetch()
                            print(f"âœ…Transcript alÄ±ndÄ±: {transcript.language}")
                            break
                        except Exception as e:
                            print(f"ğŸ“Transcript fetch hatasÄ±: {e}")
                            continue
                            
                except Exception as list_error:
                    print(f"[red]Transcript listelenemedi: {list_error}[/red]")
            
            if not fetched_transcript:
                state["error_message"] = "Video iÃ§in transcript bulunamadÄ±"
                return state
            
            # Raw data'yÄ± al ve birleÅŸtir
            raw_data = fetched_transcript.to_raw_data()
            full_transcript = " ".join([item['text'] for item in raw_data])
            state["transcript"] = full_transcript
            
            # Token sayÄ±sÄ±nÄ± gÃ¶ster
            token_count = len(self.encoding.encode(full_transcript))
            print(f"âœ…Transcript Ã§Ä±karÄ±ldÄ±: {len(full_transcript)} karakter, {token_count} token")
            
        except Exception as e:
            state["error_message"] = f"Transcript Ã§Ä±karÄ±lamadÄ±: {str(e)}"
            print(f"âŒ Hata: {state['error_message']}")
        
        return state
    
    def process_content(self, state: VideoQAState) -> VideoQAState:
        """Ä°Ã§eriÄŸi parÃ§alara ayÄ±rÄ±r ve vector store oluÅŸturur"""
        try:
            print("ğŸ”µÄ°Ã§erik iÅŸleniyor ve vector store oluÅŸturuluyor...")
            
            if not state["transcript"]:
                state["error_message"] = "Ä°ÅŸlenecek transcript bulunamadÄ±"
                return state
            
            # Metni parÃ§alara ayÄ±r
            chunks = self.text_splitter.split_text(state["transcript"])
            
            # Document objelerine Ã§evir
            documents = []
            for i, chunk in enumerate(chunks):
                doc = Document(
                    page_content=chunk,
                    metadata={
                        "video_title": state["video_title"],
                        "video_url": state["video_url"],
                        "chunk_id": i,
                        "source": "youtube_transcript"
                    }
                )
                documents.append(doc)
            
            state["chunks"] = documents
            
            # Vector store oluÅŸtur (embeddings varsa)
            if self.embeddings:
                vectorstore = FAISS.from_documents(documents, self.embeddings)
                state["vectorstore"] = vectorstore
                print(f"âœ…Ä°Ã§erik iÅŸlendi: {len(documents)} parÃ§a oluÅŸturuldu")
            else:
                print("âš ï¸âš ï¸  Embeddings olmadan devam ediliyor (basit metin aramasÄ±)")
                state["vectorstore"] = None
                print(f"âœ…Ä°Ã§erik iÅŸlendi: {len(documents)} parÃ§a oluÅŸturuldu")
            
        except Exception as e:
            state["error_message"] = f"Ä°Ã§erik iÅŸleme hatasÄ±: {str(e)}"
            print(f"âŒ Hata: {state['error_message']}")
        
        return state
    
    def search_relevant_content(self, state: VideoQAState) -> VideoQAState:
        """Soruya uygun iÃ§erikleri arar"""
        try:
            if not state["question"]:
                state["error_message"] = "Soru bulunamadÄ±"
                return state
            
            print(f"ğŸ”µSoru iÃ§in ilgili iÃ§erikler aranÄ±yor: {state['question']}")
            
            if state["vectorstore"]:
                # Vector search ile alakalÄ± iÃ§erikleri bul
                docs = state["vectorstore"].similarity_search(
                    state["question"], 
                    k=4  # En alakalÄ± 4 parÃ§ayÄ± al
                )
                relevant_chunks = [doc.page_content for doc in docs]
                print(f"âœ…Vector search ile {len(relevant_chunks)} alakalÄ± iÃ§erik bulundu")
            else:
                # Basit keyword search (embeddings yoksa)
                print("âš ï¸Basit metin aramasÄ± yapÄ±lÄ±yor...")
                question_words = state["question"].lower().split()
                relevant_chunks = []
                
                for doc in state["chunks"]:
                    content_lower = doc.page_content.lower()
                    # Soru kelimelerinin herhangi biri iÃ§erikte varsa al
                    if any(word in content_lower for word in question_words if len(word) > 2):
                        relevant_chunks.append(doc.page_content)
                
                # En fazla 4 parÃ§a al
                relevant_chunks = relevant_chunks[:4]
                
                # EÄŸer hiÃ§ bulamazsa, ilk birkaÃ§ parÃ§ayÄ± al
                if not relevant_chunks and state["chunks"]:
                    relevant_chunks = [doc.page_content for doc in state["chunks"][:3]]
                
                print(f"âœ…Basit arama ile {len(relevant_chunks)} alakalÄ± iÃ§erik bulundu")
            
            state["relevant_chunks"] = relevant_chunks
            
        except Exception as e:
            state["error_message"] = f"Ä°Ã§erik arama hatasÄ±: {str(e)}"
            print(f"âŒ Hata: {state['error_message']}")
        
        return state
    
    def extract_key_insights(self, state: VideoQAState) -> VideoQAState:
        """Video'nun ana fikirlerini Ã§Ä±karÄ±r"""
        try:
            print("ğŸ”µAna fikirler Ã§Ä±karÄ±lÄ±yor...")
            
            if not state["transcript"]:
                state["error_message"] = "Ana fikirler iÃ§in transcript bulunamadÄ±"
                return state
            
            # Transcript'in ilk yarÄ±sÄ±nÄ± al (Ã§ok uzunsa)
            transcript = state["transcript"]
            if len(transcript) > 3000:
                # Ä°lk 3000 karakteri al ve son cÃ¼mleyi tamamla
                truncated = transcript[:3000]
                last_period = truncated.rfind('.')
                if last_period > 2000:
                    transcript = truncated[:last_period + 1]
                else:
                    transcript = truncated
            
            # Ana fikirler iÃ§in prompt
            insights_prompt = f"""Sen bir video iÃ§erik analiz uzmanÄ±sÄ±n. AÅŸaÄŸÄ±daki video transcript'ini analiz ederek ana fikirleri Ã§Ä±kar.

Video: {state["video_title"]}

Transcript:
{transcript}

GÃ¶rev: Bu video'nun 3-5 temel mesajÄ±nÄ±/ana fikrini Ã§Ä±kar.

Format:
- Her ana fikir tek satÄ±rda olsun
- Net, Ã¶z ve anlaÅŸÄ±lÄ±r olsun
- TÃ¼rkÃ§e olsun
- Sadece ana fikirleri listele, aÃ§Ä±klama yapma

Ana Fikirler:
1.
2.
3.
4.
5."""
            
            response = self.llm.invoke(insights_prompt)
            insights_text = response.content
            
            # Response'u parse et
            insights = []
            lines = insights_text.strip().split('\n')
            for line in lines:
                line = line.strip()
                if line and (line.startswith(('1.', '2.', '3.', '4.', '5.', '-', 'â€¢')) or line[0].isdigit()):
                    # NumarayÄ± ve iÅŸaretleri temizle
                    clean_line = line
                    for prefix in ['1.', '2.', '3.', '4.', '5.', '-', 'â€¢']:
                        if clean_line.startswith(prefix):
                            clean_line = clean_line[len(prefix):].strip()
                            break
                    if clean_line:
                        insights.append(clean_line)
            
            # En fazla 5 ana fikir
            state["key_insights"] = insights[:5]
            
            print(f"âœ…âœ… {len(state['key_insights'])} ana fikir Ã§Ä±karÄ±ldÄ±")
            
        except Exception as e:
            state["error_message"] = f"Ana fikir Ã§Ä±karma hatasÄ±: {str(e)}"
            print(f"âŒ Hata: {state['error_message']}")
            # Hata durumunda boÅŸ liste
            state["key_insights"] = []
        
        return state
    
    def generate_answer(self, state: VideoQAState) -> VideoQAState:
        """Soruya cevap Ã¼retir"""
        try:
            if not state["relevant_chunks"] or not state["question"]:
                state["error_message"] = "AlakalÄ± iÃ§erik veya soru bulunamadÄ±"
                return state
            
            print("ğŸ”µCevap Ã¼retiliyor...")
            
            # AlakalÄ± iÃ§erikleri birleÅŸtir
            context = "\n\n".join(state["relevant_chunks"])
            
            # Gemma iÃ§in optimize edilmiÅŸ prompt
            prompt = f"""Sen bir video iÃ§erik analiz uzmanÄ±sÄ±n. AÅŸaÄŸÄ±daki video iÃ§eriÄŸini analiz ederek soruyu yanÄ±tla.

Video: {state["video_title"]}

Ä°Ã§erik:
{context}

Soru: {state["question"]}

Talimatlar:
1. Sadece verilen video iÃ§eriÄŸindeki bilgileri kullan
2. CevabÄ±nÄ± TÃ¼rkÃ§e ver
3. AÃ§Ä±k ve net ol
4. EÄŸer bilgi iÃ§erikte yoksa "Bu bilgi video iÃ§eriÄŸinde mevcut deÄŸil" de

Cevap:"""
            
            response = self.llm.invoke(prompt)
            state["answer"] = response.content
            
            # KonuÅŸma geÃ§miÅŸine ekle
            if "conversation_history" not in state:
                state["conversation_history"] = []
            
            state["conversation_history"].append({
                "question": state["question"],
                "answer": state["answer"]
            })
            
            print("âœ…Cevap Ã¼retildi")
            
        except Exception as e:
            state["error_message"] = f"Cevap Ã¼retme hatasÄ±: {str(e)}"
            print(f"âŒ Hata: {state['error_message']}")
        
        return state
    
    def _build_graph(self) -> StateGraph:
        """LangGraph workflow'unu oluÅŸturur"""
        workflow = StateGraph(VideoQAState)
        
        # Node'larÄ± ekle
        workflow.add_node("get_video_info", self.get_video_info)
        workflow.add_node("extract_transcript", self.extract_transcript)
        workflow.add_node("process_content", self.process_content)
        workflow.add_node("extract_insights", self.extract_key_insights)
        workflow.add_node("search_content", self.search_relevant_content)
        workflow.add_node("generate_answer", self.generate_answer)
        
        # Edge'leri tanÄ±mla
        workflow.add_edge("get_video_info", "extract_transcript")
        workflow.add_edge("extract_transcript", "process_content")
        workflow.add_edge("process_content", "extract_insights")
        workflow.add_edge("extract_insights", "search_content")
        workflow.add_edge("search_content", "generate_answer")
        workflow.add_edge("generate_answer", END)
        
        # BaÅŸlangÄ±Ã§ noktasÄ±
        workflow.set_entry_point("get_video_info")
        
        return workflow.compile()
    
    def process_video(self, video_url: str) -> VideoQAState:
        """Video'yu iÅŸler ve soru-cevap iÃ§in hazÄ±rlar"""
        initial_state = VideoQAState(
            video_url=video_url,
            video_title="",
            transcript="",
            chunks=[],
            vectorstore=None,
            question="",
            relevant_chunks=[],
            answer="",
            conversation_history=[],
            key_insights=[],
            error_message=""
        )
        
        # Video iÅŸleme workflow'unu Ã§alÄ±ÅŸtÄ±r (ana fikirler dahil)
        for step in ["get_video_info", "extract_transcript", "process_content", "extract_insights"]:
            if step == "get_video_info":
                result = self.get_video_info(initial_state)
            elif step == "extract_transcript":
                result = self.extract_transcript(result)
            elif step == "process_content":
                result = self.process_content(result)
            elif step == "extract_insights":
                result = self.extract_key_insights(result)
            
            if result["error_message"]:
                return result
        
        return result
    
    def ask_question(self, state: VideoQAState, question: str) -> VideoQAState:
        """Video hakkÄ±nda soru sorar"""
        state["question"] = question
        
        # Soru-cevap workflow'unu Ã§alÄ±ÅŸtÄ±r
        state = self.search_relevant_content(state)
        if state["error_message"]:
            return state
        
        state = self.generate_answer(state)
        return state
    
    def display_answer(self, state: VideoQAState):
        """CevabÄ± gÃ¼zel bir ÅŸekilde gÃ¶sterir"""
        if state["error_message"]:
            print(f"âŒ Hata: {state['error_message']}")
            return
        
        # Video bilgisi
        print(f"\nğŸ¥ Video: {state['video_title']}")
        print(f"ğŸ”— URL: {state['video_url']}")
        
        # Soru
        print(f"\nâ“ Soru: {state['question']}")
        
        # Cevap
        print(f"\nğŸ’¬ Cevap: {state['answer']}")
        print("-" * 50)

def main():
    """Ana fonksiyon"""
    print("ğŸ¤– YouTube Video Soru-Cevap Agent Sistemi")
    print("=" * 50)
    print("Bu sistem YouTube videolarÄ±ndan transcript Ã§Ä±karÄ±p, iÃ§erik hakkÄ±nda sorularÄ±nÄ±zÄ± yanÄ±tlar.")
    print("=" * 50)
    
    # Model seÃ§imi
    print("\nğŸ”§ Model seÃ§enekleri:")
    print("1. LM Studio (Yerel model)")
    print("2. Google Gemini (Bulut model)")
    
    choice = input("\nSeÃ§iminiz (1 veya 2): ").strip()
    
    if choice == "1":
        # LM Studio modu
        lm_studio_url = input("LM Studio URL'si [http://localhost:1234/v1]: ").strip()
        if not lm_studio_url:
            lm_studio_url = "http://localhost:1234/v1"
        
        model_name = input("Model adÄ± [gemma-3n-e4b]: ").strip()
        if not model_name:
            model_name = "gemma-3n-e4b"
        
        # Embedding model adÄ±
        embedding_model = input("Embedding model adÄ± [text-embedding-mxbai-embed-large-v1]: ").strip()
        if not embedding_model:
            embedding_model = "text-embedding-mxbai-embed-large-v1"
        
        print(f"âœ… LM Studio modu: {lm_studio_url}")
        print(f"âœ… LLM Model: {model_name}")
        print(f"âœ… Embedding Model: {embedding_model}")
        
        agent = YouTubeQAAgent(
            provider="lm_studio",
            lm_studio_url=lm_studio_url,
            model_name=model_name,
            embedding_model=embedding_model
        )
    else:
        # Gemini modu
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            api_key = input("Google Gemini API Key giriniz: ")
        
        # Gemini model seÃ§imi
        print("\nğŸ”§ Gemini model seÃ§enekleri:")
        print("1. gemini-2.5-flash (HÄ±zlÄ±)")
        print("2. gemini-2.5-pro (GÃ¼Ã§lÃ¼)")
        
        model_choice = input("Model seÃ§in (1 veya 2) [1]: ").strip()
        if model_choice == "2":
            model_name = "gemini-2.5-pro"
        else:
            model_name = "gemini-2.5-flash"
        
        print(f"âœ… Gemini modu")
        print(f"âœ… Model: {model_name}")
        
        agent = YouTubeQAAgent(
            api_key=api_key,
            provider="gemini",
            model_name=model_name
        )
    
    # Video URL al
    video_url = input("\nYouTube video URL'sini giriniz: ")
    
    print("\nğŸ”µ Video iÅŸleniyor...")
    
    # Video'yu iÅŸle
    state = agent.process_video(video_url)
    
    if state["error_message"]:
        print(f"âŒ Hata: {state['error_message']}")
        return
    
    print(f"\nâœ… Video baÅŸarÄ±yla iÅŸlendi: {state['video_title']}")
    print("ğŸ’¬ ArtÄ±k video hakkÄ±nda sorular sorabilirsiniz!")
    
    # Soru-cevap dÃ¶ngÃ¼sÃ¼
    while True:
        try:
            question = input("\nğŸ¤” Sorunuz (Ã§Ä±kmak iÃ§in 'q'): ")
            
            if question.lower() in ['q', 'quit', 'exit', 'Ã§Ä±k']:
                print("ğŸ‘‹ GÃ¶rÃ¼ÅŸÃ¼rÃ¼z!")
                break
            
            if not question.strip():
                continue
            
            # Soruyu yanÄ±tla
            state = agent.ask_question(state, question)
            agent.display_answer(state)
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ GÃ¶rÃ¼ÅŸÃ¼rÃ¼z!")
            break
        except Exception as e:
            print(f"âŒ Beklenmeyen hata: {e}")

if __name__ == "__main__":
    main()
